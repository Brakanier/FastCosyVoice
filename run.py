#!/usr/bin/env python3
"""
CosyVoice3 TTS - –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è streaming –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –∑–∞–º–µ—Ä–æ–º –º–µ—Ç—Ä–∏–∫

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥ inference_zero_shot –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞.
–ü—Ä–∏–º–µ–Ω—è–µ—Ç torch.compile –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è LLM –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (~2x speedup).

–ú–µ—Ç—Ä–∏–∫–∏:
- TTFB (Time To First Byte): –≤—Ä–µ–º—è –¥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞ –∞—É–¥–∏–æ
- RTF (Real-Time Factor): –≤—Ä–µ–º—è_—Å–∏–Ω—Ç–µ–∑–∞ / –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–∞—É–¥–∏–æ (< 1.0 = –±—ã—Å—Ç—Ä–µ–µ —Ä–µ–∞–ª—Ç–∞–π–º–∞)
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞—É–¥–∏–æ
- –û–±—â–µ–µ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
"""

import sys
import time
import os
import logging
from pathlib import Path

sys.path.append('third_party/Matcha-TTS')


def get_gpu_memory_stats() -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –ø–∞–º—è—Ç–∏.
    
    Returns:
        dict —Å –∫–ª—é—á–∞–º–∏: allocated_gb, reserved_gb, max_allocated_gb
    """
    import torch
    if not torch.cuda.is_available():
        return {'allocated_gb': 0.0, 'reserved_gb': 0.0, 'max_allocated_gb': 0.0}
    
    allocated = torch.cuda.memory_allocated() / (1024 ** 3)
    reserved = torch.cuda.memory_reserved() / (1024 ** 3)
    max_allocated = torch.cuda.max_memory_allocated() / (1024 ** 3)
    
    return {
        'allocated_gb': allocated,
        'reserved_gb': reserved,
        'max_allocated_gb': max_allocated,
    }


def print_gpu_memory(label: str) -> None:
    """–í—ã–≤–æ–¥–∏—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏ —Å –º–µ—Ç–∫–æ–π."""
    stats = get_gpu_memory_stats()
    print(f"\nüìä GPU –ø–∞–º—è—Ç—å [{label}]:")
    print(f"   –í—ã–¥–µ–ª–µ–Ω–æ: {stats['allocated_gb']:.2f} GB")
    print(f"   –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {stats['reserved_gb']:.2f} GB")
    print(f"   –ü–∏–∫ –≤—ã–¥–µ–ª–µ–Ω–∏—è: {stats['max_allocated_gb']:.2f} GB")

import torch
import torchaudio
from cosyvoice.cli.cosyvoice import CosyVoice3

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è torch.compile
torch.set_float32_matmul_precision('high')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—å—é
MODEL_DIR = 'pretrained_models/Fun-CosyVoice3-0.5B'

# –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª (3-10 —Å–µ–∫, —á–∏—Å—Ç–∞—è –∑–∞–ø–∏—Å—å)
REFERENCE_AUDIO = 'refs/yaga.wav'

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
OUTPUT_DIR = 'output'

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
INSTRUCTION = "You are a helpful assistant."

# –¢–µ–∫—Å—Ç—ã –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
SYNTHESIS_TEXTS = [
    "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ CosyVoice3.",
    "–í—Ç–æ—Ä–æ–π –ø—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. [cough] [cough] –ë–ª—è—Ç—å! –ù–∞–¥–æ –±—ã –±—Ä–æ—Å–∞—Ç—å –∫—É—Ä–∏—Ç—å",
    "–ò —Ç—Ä–µ—Ç–∏–π —Ç–µ–∫—Å—Ç [laughter] –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ [laughter] –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å [laughter] —Å–º–µ—Ö—É—ë—á–∫–∏.",
]


def load_prompt_text(audio_path: str, instruction: str = INSTRUCTION) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏–∑ txt —Ñ–∞–π–ª–∞ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç prompt_text.
    
    –§–æ—Ä–º–∞—Ç prompt_text: "{instruction}<|endofprompt|>{—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è}"
    """
    txt_path = audio_path.rsplit('.', 1)[0] + '.txt'
    
    with open(txt_path, 'r', encoding='utf-8') as f:
        transcription = f.read().strip()
    
    return f"{instruction}<|endofprompt|>{transcription}"


def apply_torch_compile(cosyvoice: CosyVoice3) -> None:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç torch.compile –∫ LLM –º–æ–¥–µ–ª–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.
    
    –ö–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π Qwen2ForCausalLM.model (Qwen2Model),
    –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ forward_one_step –¥–ª—è –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    """
    # –ü—É—Ç—å –∫ Qwen2Model: cosyvoice.model.llm.llm.model.model
    # llm - CosyVoice3LM
    # llm.llm - Qwen2Encoder  
    # llm.llm.model - Qwen2ForCausalLM
    # llm.llm.model.model - Qwen2Model (—Ç–æ —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ forward_one_step)
    
    qwen2_model = cosyvoice.model.llm.llm.model.model
    logger.info(f"–ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º Qwen2Model: {type(qwen2_model).__name__}")
    
    compiled_model = torch.compile(qwen2_model, mode="default")
    cosyvoice.model.llm.llm.model.model = compiled_model
    
    logger.info("torch.compile –ø—Ä–∏–º–µ–Ω—ë–Ω –∫ LLM")


def warmup_model(
    cosyvoice: CosyVoice3,
    prompt_text: str,
    spk_id: str,
) -> None:
    """
    –ü—Ä–æ–≥—Ä–µ–≤–∞–µ—Ç –º–æ–¥–µ–ª—å, –≥–µ–Ω–µ—Ä–∏—Ä—É—è —Ç–æ–∫–µ–Ω—ã –¥–ª—è –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –≤—Å–µ—Ö –ø—É—Ç–µ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
    
    torch.compile —Å–æ–∑–¥–∞—ë—Ç —Ä–∞–∑–Ω—ã–µ —è–¥—Ä–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö,
    –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–Ω–æ –ø—Ä–æ–≥—Ä–µ—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã.
    
    Args:
        cosyvoice: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å CosyVoice3
        prompt_text: –¢–µ–∫—Å—Ç prompt'–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        spk_id: ID —Å–ø–∏–∫–µ—Ä–∞ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω —á–µ—Ä–µ–∑ add_zero_shot_spk)
    """
    # –¢–µ–∫—Å—Ç—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    warmup_texts = [
        # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (~50-100 LLM —Ç–æ–∫–µ–Ω–æ–≤)
        "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
        # –°—Ä–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç (~100-200 LLM —Ç–æ–∫–µ–Ω–æ–≤)  
        "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ä–µ–¥–Ω–µ–π –¥–ª–∏–Ω—ã –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞ –º–æ–¥–µ–ª–∏.",
        # –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (~200-400 LLM —Ç–æ–∫–µ–Ω–æ–≤)
        "–≠—Ç–æ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞. " * 3,
        # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (~400+ LLM —Ç–æ–∫–µ–Ω–æ–≤)
        "–ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –¥–ª–∏–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –¥–ª—è –∫–æ–º–ø–∏–ª—è—Ü–∏–∏. " * 5,
    ]
    
    warmup_start = time.time()
    
    # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ - –æ—Å–Ω–æ–≤–Ω–∞—è –∫–æ–º–ø–∏–ª—è—Ü–∏—è
    logger.info("–ü—Ä–æ–≥—Ä–µ–≤: –ø–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ (–∫–æ–º–ø–∏–ª—è—Ü–∏—è —è–¥–µ—Ä)...")
    for i, text in enumerate(warmup_texts):
        logger.info(f"  –ü—Ä–æ–≥—Ä–µ–≤ —Ç–µ–∫—Å—Ç {i+1}/{len(warmup_texts)}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        for _ in cosyvoice.inference_zero_shot(
            tts_text=text,
            prompt_text=prompt_text,
            prompt_wav=REFERENCE_AUDIO,
            zero_shot_spk_id=spk_id,
            stream=True,
        ):
            pass  # –ü—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
    
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    
    # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ - —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Å–µ –ø—É—Ç–∏ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω—ã
    logger.info("–ü—Ä–æ–≥—Ä–µ–≤: –≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ (—Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è)...")
    for text in warmup_texts:
        for _ in cosyvoice.inference_zero_shot(
            tts_text=text,
            prompt_text=prompt_text,
            prompt_wav=REFERENCE_AUDIO,
            zero_shot_spk_id=spk_id,
            stream=True,
        ):
            pass
    
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    
    warmup_time = time.time() - warmup_start
    logger.info(f"–ü—Ä–æ–≥—Ä–µ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {warmup_time:.2f} —Å–µ–∫")


def synthesize_streaming(
    cosyvoice: CosyVoice3,
    text: str,
    prompt_text: str,
    spk_id: str,
    sample_rate: int,
    output_path: str
) -> dict:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç streaming —Å–∏–Ω—Ç–µ–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ zero_shot –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏.
    
    Args:
        prompt_text: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "{instruction}<|endofprompt|>{—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è}"
    
    Returns:
        dict —Å –∫–ª—é—á–∞–º–∏: ttfb, total_time, audio_duration, rtf, chunk_count
    """
    start_time = time.time()
    first_chunk_time = None
    audio_chunks = []
    chunk_count = 0
    
    for model_output in cosyvoice.inference_zero_shot(
        tts_text=text,
        prompt_text=prompt_text,
        prompt_wav=REFERENCE_AUDIO,
        zero_shot_spk_id=spk_id,
        stream=True,
    ):
        chunk_count += 1
        
        if first_chunk_time is None:
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            first_chunk_time = time.time() - start_time
        
        speech = model_output['tts_speech']
        audio_chunks.append(speech)
    
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    
    total_time = time.time() - start_time
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞–Ω–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    if audio_chunks:
        full_audio = torch.cat(audio_chunks, dim=1)
        torchaudio.save(output_path, full_audio, sample_rate)
        audio_duration = full_audio.shape[1] / sample_rate
    else:
        audio_duration = 0.0
    
    rtf = total_time / audio_duration if audio_duration > 0 else float('inf')
    
    return {
        'ttfb': first_chunk_time or 0.0,
        'total_time': total_time,
        'audio_duration': audio_duration,
        'rtf': rtf,
        'chunk_count': chunk_count,
    }


def main():
    print("=" * 70)
    print("CosyVoice3 TTS - Streaming Inference (zero_shot)")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
    if not os.path.exists(MODEL_DIR):
        logger.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_DIR}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ
    if not os.path.exists(REFERENCE_AUDIO):
        logger.error(f"–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π –∞—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω: {REFERENCE_AUDIO}")
        return
    
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    Path(OUTPUT_DIR).mkdir(exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º prompt_text –∏–∑ txt —Ñ–∞–π–ª–∞ —Ä—è–¥–æ–º —Å –∞—É–¥–∏–æ
    prompt_text = load_prompt_text(REFERENCE_AUDIO, INSTRUCTION)
    
    print(f"\nüé§ –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π –∞—É–¥–∏–æ: {REFERENCE_AUDIO}")
    print(f"üìù –¢–µ–∫—Å—Ç–æ–≤ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞: {len(SYNTHESIS_TEXTS)}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π)
    print("\nüîß –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    load_start = time.time()
    
    cosyvoice = CosyVoice3(
        model_dir=MODEL_DIR,
        fp16=True,
        load_vllm=False,
        load_trt=True,
    )
    
    load_time = time.time() - load_start
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫")
    
    print_gpu_memory("–ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏")
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ dtype
    llm_dtype = next(cosyvoice.model.llm.parameters()).dtype
    flow_dtype = next(cosyvoice.model.flow.parameters()).dtype
    hift_dtype = next(cosyvoice.model.hift.parameters()).dtype
    print(f"üìä LLM dtype: {llm_dtype}, Flow dtype: {flow_dtype}, HiFT dtype: {hift_dtype}")
    
    sample_rate = cosyvoice.sample_rate
    print(f"üìä Sample rate: {sample_rate} Hz")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º torch.compile –∫ LLM
    print("\n‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ torch.compile –∫ LLM...")
    compile_start = time.time()
    apply_torch_compile(cosyvoice)
    compile_time = time.time() - compile_start
    print(f"‚úÖ torch.compile –ø—Ä–∏–º–µ–Ω—ë–Ω –∑–∞ {compile_time:.3f} —Å–µ–∫")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–ø–∏–∫–µ—Ä–∞ (–æ–¥–∏–Ω —Ä–∞–∑)
    print("\nüéØ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–ø–∏–∫–µ—Ä–∞...")
    spk_id = "reference_speaker"
    embed_start = time.time()
    cosyvoice.add_zero_shot_spk(prompt_text, REFERENCE_AUDIO, spk_id)
    embed_time = time.time() - embed_start
    print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∑–∞ {embed_time:.3f} —Å–µ–∫")
    
    # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ (–∫–æ–º–ø–∏–ª—è—Ü–∏—è –≥—Ä–∞—Ñ–æ–≤)
    print("\nüî• –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ (–∫–æ–º–ø–∏–ª—è—Ü–∏—è –≥—Ä–∞—Ñ–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–ª–∏–Ω —Ç–µ–∫—Å—Ç–∞)...")
    warmup_model(cosyvoice, prompt_text, spk_id)
    print("‚úÖ –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥—Ä–µ—Ç–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
    
    print_gpu_memory("–ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞")
    
    # –°–±—Ä–æ—Å —Å—á—ë—Ç—á–∏–∫–∞ –ø–∏–∫–æ–≤–æ–π –ø–∞–º—è—Ç–∏ –¥–ª—è –∑–∞–º–µ—Ä–∞ —Ç–æ–ª—å–∫–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º —Ç–µ–∫—Å—Ç–∞–º
    all_metrics = []
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
    for idx, text in enumerate(SYNTHESIS_TEXTS, 1):
        print("\n" + "=" * 70)
        print(f"üìÑ –¢–µ–∫—Å—Ç {idx}/{len(SYNTHESIS_TEXTS)}")
        print("=" * 70)
        print(f"üìù {text[:80]}{'...' if len(text) > 80 else ''}")
        
        output_file = os.path.join(OUTPUT_DIR, f'output_{idx:02d}.wav')
        
        try:
            metrics = synthesize_streaming(
                cosyvoice=cosyvoice,
                text=text,
                prompt_text=prompt_text,  # —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ
                spk_id=spk_id,
                sample_rate=sample_rate,
                output_path=output_file,
            )
            
            all_metrics.append(metrics)
            
            print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file}")
            print("\nüìä –ú–ï–¢–†–ò–ö–ò:")
            print("-" * 40)
            print(f"‚ö° TTFB:             {metrics['ttfb']:.3f} —Å–µ–∫")
            print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è:      {metrics['total_time']:.3f} —Å–µ–∫")
            print(f"üéµ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:     {metrics['audio_duration']:.3f} —Å–µ–∫")
            print(f"üìà RTF:              {metrics['rtf']:.3f}")
            print(f"üì¶ –ß–∞–Ω–∫–æ–≤:           {metrics['chunk_count']}")
            
            if metrics['rtf'] < 1.0:
                print(f"‚úÖ –ë—ã—Å—Ç—Ä–µ–µ —Ä–µ–∞–ª—Ç–∞–π–º–∞ –≤ {1/metrics['rtf']:.1f}x")
            else:
                print(f"‚ö†Ô∏è  –ú–µ–¥–ª–µ–Ω–Ω–µ–µ —Ä–µ–∞–ª—Ç–∞–π–º–∞ –≤ {metrics['rtf']:.1f}x")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ç–µ–∑–µ —Ç–µ–∫—Å—Ç–∞ #{idx}: {e}", exc_info=True)
            continue
    
    print_gpu_memory("–ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
    if all_metrics:
        print("\n" + "=" * 70)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
        print("=" * 70)
        
        avg_ttfb = sum(m['ttfb'] for m in all_metrics) / len(all_metrics)
        avg_rtf = sum(m['rtf'] for m in all_metrics) / len(all_metrics)
        total_audio = sum(m['audio_duration'] for m in all_metrics)
        total_time = sum(m['total_time'] for m in all_metrics)
        
        print(f"–°—Ä–µ–¥–Ω–∏–π TTFB:        {avg_ttfb:.3f} —Å–µ–∫")
        print(f"–°—Ä–µ–¥–Ω–∏–π RTF:         {avg_rtf:.3f}")
        print(f"–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:  {total_audio:.3f} —Å–µ–∫")
        print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è:         {total_time:.3f} —Å–µ–∫")
    
    print("\n" + "=" * 70)
    print("‚úÖ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 70)
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {OUTPUT_DIR}/")
    
    print_gpu_memory("–≤ –∫–æ–Ω—Ü–µ")


if __name__ == '__main__':
    main()

